---
title: A Neural Network is learning
description: Basics of Neural Networks and Deep Learning 04
topic: tech-deep-learning-course
date: "2024-02-08"
published: false
---

# Basics of Neural Networks and Deep Learning - Part 4

> Course Overview: [Deep Learning Course - Overview](/blog/deep-learning-course)

We will learn how Neural Networks are learning (gradient descent etc.).

## Content of this "block"
The **marked** article is the current one.

- Our Brain and the Perceptron
- MNIST, and why good data is so important
- Structure of a Neural Network
- **A Neural Network is learning**
- Backpropagation

## How is a Neural Network learning?

There are a few ways for a NN to learn:
 - Supervised Learning
 - Unsupervised Learning
 - Reinforcement Learning

Let's take a look at them.

### Supervised Learning

This method is usually used for classification tasks, 
e.g. our first project, where we will let the NN clasify images of numbers.  
Another example is spam detection.

This is basically what we have been talking about previously regarding training.

The NN gets the data and the corresponding label.

### Unsupervised Learning

With this method we usually try to detect pattern in data 
and get a rule for this pattern.  
Used in for example recommendation systems.

Here the NN only gets the data.

### Reinforcement Learning

Reinforcement learning is used to get a NN to work in a real or simulated environment,
for example warehouse robots.
The NN gets no data, but everything the NN does in a simulated environment is rated.


## How are we rating out Neural Network

To tell the NN if  it's on the right way, we need to somehow calculate the loss.
For this we will use an error-function or loss function, which is quite an important component when developing a NN.

The easiest errorfunction is the following:

e.g. `loss = | <right solution> - <calculated solution> |`

We will never use this, as it is easy.

We can change this to a more complicated function when for eample squaring the result.
This would punish errors more.

> Example:
> 
> TODO

---

Our goal is minimizing the errorfunction, i.e. get a small error.
For a normal function this would be the derivation.

> TODO If you need to revive derivation: link derivation

With the derivation we can get the extreme points of a function, 
i.e. the minima and maxima.

When we insert the x-values into the errorfunction we get the point,
i.e. we know if the extreme point is a maximum or minimum.

## Gradient Descent

With all our weights, biases and thresholds, we have much more variables than in a normal function.
To make all this more related to the learning process, 
we'll take two variables for our example-error-function, 
i.e. three-dimensional space.

To find the minimum, we will use the gradient.  
The gradient is a vektor which components are the values 
of the partial derivation of the function *f*.

Instead of the derivation of the function we need the partial derivation for every variable,
so we know which variable makes the greatest change.

*I will explain this detailed in the backpropagation article (the next one)*

What we need to know:

When a funtion has many variables and is derivated to one variable, it's a partial derivation.

---

The gradient will give us the greatest incrase of the function, starting of in one point.

TODO: image

As we want to find the minimum of the function, we can use the negative gradient,
i.e. always go into the opposite direct of the gradient.

As the gradient is the way of the quick increase, the negative gradient is the way of quickest decrease.

```python
# Example gradient vector

vector = [
    0.2,
    0.15,
    3.14,
    -0.5,
    0.1,
]
```

The gradient tells us which variables are most important / make the greatest change.

Adjusting the variables with the gradient is called **gradient descent**

w' = w - n (learning rate) * gradient

important small steps image TODO

we make gradient descent until we get to a minimum

problem local vs globale minimum

when stuck in a lokal minimum, we won't find the global minimum, because the gradient descent routes us to the local minimum.

no solution, not too big of a problem.

## initialisation

optimal point would be great, but we don't know how, so:

-> random values, in some specific range (so we don't have some extrme randow values)

oc no good result with this, but after training hopefully

### why not all the same

when the starting variables are the same, we don#t know which to change with the gradient descent, because alle are the same

## random info (i will move this to MNIST article probably)

one time through all training data = "epoch"


## classification
TODO: accuracy, loss explanation

accuracy = correct classification / all classifications

we can use small parts of the test data whhile training, to get acc/loss between epochs.